{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project which I did for a summer school course on machine learning applied to speech technology, at the University of Eastern Finland.\n",
    "\n",
    "The goal of this task is to try to determine whether subjects have Parkinson’s Disease, using a neural network with input features extracted from speech recordings. The recordings involve the subjects saying “Ahhh” into their iPhone microphones for several seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that the correct version of Python is running (3.5)\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import scipy.io.wavfile\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read & Extract Info from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Put in path to pd-data folder here\n",
    "datapath = \"~/uef/data/pd-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read CSV data file\n",
    "raw_data = pd.read_csv('~/uef/data/pd-data/dataset.csv', delimiter=\";\")\n",
    "#print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert panda object columns into np arrays\n",
    "ids = np.array(raw_data['id'])\n",
    "ages = np.array(raw_data['age'])\n",
    "times = np.array(raw_data['time'])\n",
    "pds_string = np.array(raw_data['pd'])\n",
    "evals = np.array(raw_data['eval'])\n",
    "files = np.array(raw_data['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert string entries for the PD column into 1's and 0's\n",
    "pds = np.zeros(pds_string.shape)\n",
    "for i in range(0,len(pds_string)):\n",
    "    if pds_string[i] == 'True':\n",
    "        pds[i] = 1\n",
    "    elif pds_string[i] == 'False':\n",
    "        pds[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since I only have audio files up to entry #nn, select only the first nn entries\n",
    "n_temp = nn #(put value in here)\n",
    "\n",
    "ids = ids[:n_temp]\n",
    "ages = ages[:n_temp]\n",
    "times = times[:n_temp]\n",
    "pds = pds[:n_temp]\n",
    "evals = evals[:n_temp]\n",
    "files = files[:n_temp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "#           Feature Extraction                   #\n",
    "##################################################\n",
    "\n",
    "# Some of these functions were adapted from the Front-End Feature Extraction notebook used in class.\n",
    "\n",
    "def read_file(file_name, sample_rate):\n",
    "    X_orig, sample_rate = librosa.load(file_name, sr=sample_rate)\n",
    "    return X_orig, sample_rate\n",
    "\n",
    "def extract_feature(X, sample_rate_new):\n",
    "    #X = librosa.effects.trim(X_orig, top_db=60)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = librosa.feature.mfcc(y=X, sr=sample_rate_new, n_mfcc=40)\n",
    "    chroma = librosa.feature.chroma_stft(S=stft, sr=sample_rate_new)\n",
    "    #mel = librosa.feature.melspectrogram(X, sr=sample_rate)\n",
    "    #contrast = librosa.feature.spectral_contrast(S=stft, sr=sample_rate)\n",
    "    #tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=X)\n",
    "    #return mfccs,chroma,mel,contrast,tonnetz\n",
    "    #return mfccs, chroma, mel, contrast, tonnetz\n",
    "    return mfccs, chroma, zero_crossing_rate\n",
    "    #return zero_crossing_rate\n",
    "\n",
    "def squared_derivative(matrix, step):\n",
    "    ## Calculate the \"derivative\":\n",
    "    ## the difference between a feature at one time step and the previous time step.\n",
    "    ## Square it because I'm interested in the magnitude, not sign\n",
    "    ## Step is the time scale over which the \"derivative\" is taken:\n",
    "    ## We take feature[t] - feature[t-step].\n",
    "    \n",
    "    n_rows = matrix.shape[0]\n",
    "    n_frames = matrix.shape[1]\n",
    "    dev_sq = np.zeros([n_rows, n_frames-step])\n",
    "    for i in range(0,n_rows):\n",
    "        for j in range(step,n_frames):\n",
    "            diff = matrix[i,j] - matrix[i, j-step]\n",
    "            dev_sq[i,j-step] = diff**2\n",
    "    return dev_sq\n",
    "\n",
    "def mean_stddev(matrix, n_ignore):\n",
    "    ## Calculate mean and standard deviation over all time steps (axis 1).\n",
    "    ## n_ignore is if we want to ignore certain time steps, say the first, for whatever reason\n",
    "    ## Matrix is 2D: n_features x n_time_steps\n",
    "    \n",
    "    means = np.mean(matrix[:,n_ignore:], axis=1)\n",
    "    stddevs = np.std(matrix[:,n_ignore:], axis=1)\n",
    "    \n",
    "    return means, stddevs\n",
    "\n",
    "def mean_stddev_list(thelist, n_ignore):\n",
    "    ## For a list of arrays corresponding to features over time steps for different sound files,\n",
    "    ## Calculate mean and standard deviation over all time steps\n",
    "    ## The list is a list over sound files\n",
    "    ## Each element of the list is a 2D array: n_features x n_time_steps\n",
    "    \n",
    "    meansarr = np.array([])\n",
    "    stddevsarr = np.array([])\n",
    "    for i in range(0, len(thelist)):\n",
    "        means, stddevs = mean_stddev(thelist[i], n_ignore)\n",
    "        if (i == 0):\n",
    "            meansarr = np.copy(means)\n",
    "            stddevsarr = np.copy(stddevs)\n",
    "        else:\n",
    "            meansarr = np.vstack((meansarr, means))\n",
    "            stddevsarr = np.vstack((stddevsarr, stddevs))\n",
    "        \n",
    "    return meansarr, stddevsarr\n",
    "\n",
    "def squared_derivative_list(thelist, step):\n",
    "    ## For a list of arrays corresponding to features over time steps for different sound files,\n",
    "    ## Calculate squared derivative\n",
    "    \n",
    "    dev_sqarr = []\n",
    "    for ele in thelist:\n",
    "        dev_sq = squared_derivative(ele, step)\n",
    "        dev_sqarr.append(dev_sq)\n",
    "\n",
    "    return dev_sqarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract basic features: MFCCs, Chroma, Zero Crossing Rate\n",
    "sr = 16000\n",
    "mfccsarr = []\n",
    "chromaarr = []\n",
    "zerocrossingarr = []\n",
    "i_count_arr = []\n",
    "for i_count in range(0, len(files)):\n",
    "    file = files[i_count]\n",
    "    if (np.mod(i_count,100) == 0):\n",
    "        print(i_count)\n",
    "    X_orig, sample_rate = read_file(datapath+file, sr)\n",
    "    if (len(X_orig) == 0):\n",
    "        print(\"Zero length\")\n",
    "        continue\n",
    "    X = (librosa.effects.trim(X_orig, top_db=35))[0] # Remove silence regions (35 dB below maximum in file)\n",
    "    mfccs, chroma, zero_crossing_rate = extract_feature(X, sr) # Extract features\n",
    "    \n",
    "    mfccsarr.append(mfccs)\n",
    "    chromaarr.append(chroma)\n",
    "    zerocrossingarr.append(zero_crossing_rate)\n",
    "    i_count_arr.append(i_count) # i_count keeps track of which indexes have had features successfully extracted\n",
    "                                # i.e. those which don't have empty sound files\n",
    "    i_count = i_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save basic features in files\n",
    "with open(\"./saved_objects/icountarr\", \"wb\") as fp:\n",
    "    pickle.dump(i_count_arr, fp)\n",
    "with open(\"./saved_objects/mfccsarr\", \"wb\") as fp:\n",
    "    pickle.dump(mfccsarr, fp)\n",
    "with open(\"./saved_objects/chromaarr\", \"wb\") as fp:\n",
    "    pickle.dump(chromaarr, fp)\n",
    "with open(\"./saved_objects/zerocrossingarr\", \"wb\") as fp:\n",
    "    pickle.dump(zerocrossingarr, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load basic features from files\n",
    "with open(\"./saved_objects/icountarr\", \"rb\") as fp:\n",
    "    i_count_arr = pickle.load(fp)\n",
    "with open(\"./saved_objects/mfccsarr\", \"rb\") as fp:\n",
    "    mfccsarr = pickle.load(fp)\n",
    "with open(\"./saved_objects/chromaarr\", \"rb\") as fp:\n",
    "    chromaarr = pickle.load(fp)\n",
    "with open(\"./saved_objects/zerocrossingarr\", \"rb\") as fp:\n",
    "    zerocrossingarr = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the np arrays containing info from the CSV file,\n",
    "# We need to remove those entries which had zero-length sound files (no features extracted)\n",
    "\n",
    "ids_new = np.array([])\n",
    "ages_new = np.array([])\n",
    "times_new = np.array([])\n",
    "pds_new = np.array([])\n",
    "evals_new = np.array([])\n",
    "files_new = np.array([])\n",
    "for i in range(0, len(i_count_arr)):\n",
    "    index = i_count_arr[i]\n",
    "    \n",
    "    ids_new = np.append(ids_new, ids[index])\n",
    "    ages_new = np.append(ages_new, ages[index])\n",
    "    times_new = np.append(times_new, times[index])\n",
    "    pds_new = np.append(pds_new, pds[index])\n",
    "    evals_new = np.append(evals_new, evals[index])\n",
    "    files_new = np.append(files_new, files[index])\n",
    "\n",
    "ids = ids_new\n",
    "ages = ages_new\n",
    "times = times_new\n",
    "pds = pds_new\n",
    "evals = evals_new\n",
    "files = files_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Calculations on Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation of features\n",
    "mfccs_meansarr, mfccs_stddevsarr = mean_stddev_list(mfccsarr, 0)\n",
    "chroma_meansarr, chroma_stddevsarr = mean_stddev_list(chromaarr, 0)\n",
    "zerocrossing_meansarr, zerocrossing_stddevsarr = mean_stddev_list(zerocrossingarr, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute derivatives, and mean and stddev of derivatives, of features\n",
    "step = 1\n",
    "mfccs_devrarr = squared_derivative_list(mfccsarr, step)\n",
    "chroma_devrarr = squared_derivative_list(chromaarr, step)\n",
    "zerocrossing_devrarr = squared_derivative_list(zerocrossingarr, step)\n",
    "mfccs_devr_meanarr, mfccs_devr_stddevarr = mean_stddev_list(mfccs_devrarr, 0)\n",
    "chroma_devr_meanarr, chroma_devr_stddevarr = mean_stddev_list(chroma_devrarr, 0)\n",
    "zerocrossing_devr_meanarr, zerocrossing_devr_stddevarr = mean_stddev_list(zerocrossing_devrarr, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute derivatives with a different step size, and mean and stddev of derivatives, of features\n",
    "step = 2\n",
    "mfccs_devrarr2 = squared_derivative_list(mfccsarr, step)\n",
    "chroma_devrarr2 = squared_derivative_list(chromaarr, step)\n",
    "zerocrossing_devrarr2 = squared_derivative_list(zerocrossingarr, step)\n",
    "mfccs_devr_meanarr2, mfccs_devr_stddevarr2 = mean_stddev_list(mfccs_devrarr2, 0)\n",
    "chroma_devr_meanarr2, chroma_devr_stddevarr2 = mean_stddev_list(chroma_devrarr2, 0)\n",
    "zerocrossing_devr_meanarr2, zerocrossing_devr_stddevarr2 = mean_stddev_list(zerocrossing_devrarr2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reduce number of MFCCs, if I wish\n",
    "newnum = 13\n",
    "mfccs_meansarr_red = mfccs_meansarr[:,0:newnum]\n",
    "mfccs_stddevsarr_red = mfccs_stddevsarr[:,0:newnum]\n",
    "mfccs_devr_meanarr_red = mfccs_devr_meanarr[:,0:newnum]\n",
    "mfccs_devr_stddevarr_red = mfccs_devr_stddevarr[:,0:newnum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Features for Feeding into NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all relevant features into a single array to feed into NN:\n",
    "featurearr = np.array([])\n",
    "for i in range(0, mfccs_meansarr.shape[0]):\n",
    "    featurelist = np.concatenate((mfccs_stddevsarr[i,:], \\\n",
    "                                  mfccs_devr_meanarr[i,:], \\\n",
    "                                  chroma_devr_meanarr[i,:], zerocrossing_devr_meanarr[i,:],\n",
    "                                  mfccs_meansarr[i,:]), 0)\n",
    "    if (i==0):\n",
    "        featurearr = np.copy(featurelist)\n",
    "    else:\n",
    "        featurearr = np.vstack((featurearr, featurelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check shape of feature array\n",
    "featurearr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalise data by subtracting mean and dividing by standard deviation\n",
    "epsilon = 1e-8 # to prevent division by zero\n",
    "featurearr_norm = np.zeros_like(featurearr)\n",
    "for i in range (0,featurearr.shape[1]):\n",
    "    featurearr_norm[:,i] = (featurearr[:,i]-np.mean(featurearr[:,i]))/(np.std(featurearr[:,i] + epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Training, Validation, Evaluation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into evaluation and training-validation sets\n",
    "# Note: Evaluation set is the one for which the \"eval\" column says \"True\"\n",
    "# I will use the rest for experimentation, by splitting it into training and validation sets\n",
    "\n",
    "Y_eval = pds[np.where(evals == True)]\n",
    "X_eval = featurearr_norm[np.where(evals == True)]\n",
    "Y_trainval = pds[np.where(evals == False)]\n",
    "X_trainval = featurearr_norm[np.where(evals == False)]\n",
    "speakers_trainval = ids[np.where(evals == False)] # Speaker ids who are not in eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split non-evaluation data again into training and validation sets\n",
    "# Ensure that the same speaker doesn't go into both sets (i.e. each speaker is only in one set)\n",
    "\n",
    "train_val_ratio = 1.5 # 60% training data; 40% validation data\n",
    "epsilon = 1e-6 # To prevent division by zero\n",
    "train_id_list = np.array([]) #Speaker ids assigned to training set\n",
    "val_id_list = np.array([]) #Speaker ids assigned to validation set\n",
    "X_train = np.array([])\n",
    "Y_train = np.array([])\n",
    "X_validation = np.array([])\n",
    "Y_validation = np.array([])\n",
    "istrain = True\n",
    "\n",
    "for i in range(0, len(speakers_trainval)):\n",
    "    speaker = speakers_trainval[i]\n",
    "    #print(speaker in train_id_list)\n",
    "    if speaker in train_id_list:\n",
    "        # If speaker is already assigned to training set, all his subsequent recordings are too\n",
    "        istrain = True\n",
    "    elif speaker in val_id_list:\n",
    "        # If speaker is already assigned to validation set, all his subsequent recordings are too\n",
    "        istrain = False\n",
    "    else:\n",
    "        # If we have more training points than we wanted, assign next speaker to validation set\n",
    "        if (len(Y_train)/(len(Y_validation) + epsilon) > 1.5):\n",
    "            istrain = False\n",
    "        # Otherwise assign to training set\n",
    "        else:\n",
    "            istrain = True\n",
    "    if istrain:\n",
    "        if (len(X_train) == 0):\n",
    "            X_train = X_trainval[i,:]\n",
    "        else:\n",
    "            X_train = np.vstack((X_train, X_trainval[i,:]))\n",
    "        Y_train = np.append(Y_train, Y_trainval[i])\n",
    "        train_id_list = np.append(train_id_list, speaker)\n",
    "    else:\n",
    "        if (len(X_validation) == 0):\n",
    "            X_validation = X_trainval[i,:]\n",
    "        else:\n",
    "            X_validation = np.vstack((X_validation, X_trainval[i,:]))\n",
    "        Y_validation = np.append(Y_validation, Y_trainval[i])\n",
    "        val_id_list = np.append(val_id_list, speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check training and validation set sizes, indeed they are at a ratio of 1.5\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that the ratio of PD vs. non-PD in the training set, validation set, and all data is about the same\n",
    "Y_pd_train = Y_train[np.where(Y_train == 1)]\n",
    "print(Y_pd_train.shape)\n",
    "Y_nopd_train = Y_train[np.where(Y_train == 0)]\n",
    "print(Y_nopd_train.shape)\n",
    "Y_pd_val = Y_validation[np.where(Y_validation == 1)]\n",
    "print(Y_pd_val.shape)\n",
    "Y_nopd_val = Y_validation[np.where(Y_validation == 0)]\n",
    "print(Y_nopd_val.shape)\n",
    "haspd = pds[np.where(pds == 1)]\n",
    "nopd = pds[np.where(pds == 0)]\n",
    "print(haspd.shape)\n",
    "print(nopd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell contains code that I copied/adapted from Anssi's eval_script.py, \n",
    "# so that I can use it to calculated EER and AUROC without writing things into files\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ['SIDEKIT'] = 'theano=false,libsvm=false'\n",
    "\n",
    "import numpy as np\n",
    "import sidekit\n",
    "import sklearn.metrics\n",
    "\n",
    "def pmiss_pfs_eer(tar, non_tar):\n",
    "    minDCF, Pmiss, Pfa, prbep, eer = sidekit.bosaris.detplot.fast_minDCF(\n",
    "        tar, non_tar, np.log(0.001), normalize=True)\n",
    "    return eer\n",
    "\n",
    "def compute_auroc(tar, non_tar):\n",
    "    scores = np.hstack((tar,non_tar))\n",
    "    classes = np.hstack((np.ones(tar.shape), np.zeros(non_tar.shape)))\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(classes, scores)\n",
    "    auroc = sklearn.metrics.auc(fpr, tpr)\n",
    "    return auroc\n",
    "\n",
    "def compute_eer_and_auroc(pos, neg):\n",
    "    eer = pmiss_pfs_eer(pos,neg)\n",
    "    auroc = compute_auroc(pos, neg)\n",
    "    \n",
    "    print(\"EER: %f\" % eer)\n",
    "    print(\"AUROC: %f\" % auroc)\n",
    "    \n",
    "    return eer, auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define the model\n",
    "\n",
    "def define_model(X_train):\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(Dense(units=64, input_dim=X_train.shape[1], activation=\"tanh\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=32, activation=\"tanh\", kernel_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=16, activation=\"tanh\", kernel_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(Dropout(0.1))\n",
    "    #model.add(Dense(units=8, activation=\"tanh\", kernel_regularizer=regularizers.l1(0.001)))\n",
    "    #model.add(Dropout(0.1))\n",
    "    #model.add(Dense(units=4, activation=\"tanh\", kernel_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "    #model.add(Dense(units=4, activation=\"tanh\"))\n",
    "    #model.add(Dropout(0.25))\n",
    "    #kernel_regularizer=regularizers.l2(0.02)\n",
    "    #model.add(Dense(units=128, activation=\"relu\"))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation=\"sigmoid\", kernel_regularizer=regularizers.l1(0.01)))\n",
    "    #model.add(Dense(units=1, input_dim=X_train.shape[1], activation=\"sigmoid\", kernel_regularizer=regularizers.l2(1.0)))\n",
    "\n",
    "    opt = optimizers.RMSprop(lr=0.001)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=opt,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## A function that runs the model training several times, \n",
    "## and calculates the average EER and AUROC on the validation set\n",
    "## Since these values are somewhat dependent on the initialisation conditions\n",
    "## Use this to select model parameters, feature sets\n",
    "\n",
    "def model_auroc(X_train, Y_train, X_validation, Y_validation, n_times):\n",
    "    eer_total = 0\n",
    "    auroc_total = 0\n",
    "    for i in range(0, n_times):\n",
    "        model = define_model(X_train)\n",
    "        model.fit(X_train, Y_train, epochs=70, batch_size=256, validation_data = (X_validation, Y_validation))\n",
    "        \n",
    "        Y_predictions = model.predict(X_train)\n",
    "        Y_validation_predictions = model.predict(X_validation)\n",
    "        positives = np.ravel(Y_validation_predictions[np.where(Y_validation == 1)])\n",
    "        negatives = np.ravel(Y_validation_predictions[np.where(Y_validation == 0)])\n",
    "        eer, auroc = compute_eer_and_auroc(positives, negatives)\n",
    "        eer_total = eer_total + eer\n",
    "        auroc_total = auroc_total + auroc\n",
    "        \n",
    "    eer_average = eer_total/n_times\n",
    "    auroc_average = auroc_total/n_times\n",
    "    return eer_average, auroc_average, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eer_average, auroc_average, model = model_auroc(X_train, Y_train, X_validation, Y_validation, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Average EER: %f\" % eer_average)\n",
    "print(\"Average AUROC: %f\" % auroc_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Some Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just run the training process once for this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## If I just want to run the training process once, I use this\n",
    "\n",
    "model = define_model(X_train)\n",
    "model.fit(X_train, Y_train, epochs=70, batch_size=256, validation_data = (X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_predictions = model.predict(X_train)\n",
    "Y_validation_predictions = model.predict(X_validation)\n",
    "positives = np.ravel(Y_validation_predictions[np.where(Y_validation == 1)])\n",
    "negatives = np.ravel(Y_validation_predictions[np.where(Y_validation == 0)])\n",
    "compute_eer_and_auroc(positives, negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare AUROC for training set and validation set\n",
    "print(metrics.roc_auc_score(Y_train, Y_predictions))\n",
    "print(metrics.roc_auc_score(Y_validation, Y_validation_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use a threshold to convert prediction score to binary classifier\n",
    "## So that I can calculate confusion matrix\n",
    "def cont_to_binary(arr):\n",
    "    threshold = 0.5\n",
    "    arr_binary = np.zeros_like(arr)\n",
    "    for i in range(0, len(arr)):\n",
    "        if arr[i] < threshold:\n",
    "            arr_binary[i] = 0\n",
    "        else:\n",
    "            arr_binary[i] = 1\n",
    "    return arr_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_class = cont_to_binary(Y_predictions)\n",
    "Y_validation_pred_class = cont_to_binary(Y_validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Confusion matrix for training set \n",
    "print(metrics.classification_report(Y_train, Y_pred_class))\n",
    "print(metrics.confusion_matrix(Y_train, Y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Confusion matrix for validation set\n",
    "print(metrics.classification_report(Y_validation, Y_validation_pred_class))\n",
    "print(metrics.confusion_matrix(Y_validation, Y_validation_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Evaluation Set Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## A function that runs the model training several times, \n",
    "## and calculates the average EER and AUROC on the evaluation set\n",
    "## Use this to calculate final evaluation score\n",
    "\n",
    "def model_auroc(X_train, Y_train, X_eval, Y_eval, n_times):\n",
    "    eer_total = 0\n",
    "    auroc_total = 0\n",
    "    for i in range(0, n_times):\n",
    "        model = define_model(X_train)\n",
    "        model.fit(X_train, Y_train, epochs=70, batch_size=256)\n",
    "        \n",
    "        Y_predictions = model.predict(X_train)\n",
    "        Y_eval_predictions = model.predict(X_eval)\n",
    "        positives = np.ravel(Y_eval_predictions[np.where(Y_eval == 1)])\n",
    "        negatives = np.ravel(Y_eval_predictions[np.where(Y_eval == 0)])\n",
    "        eer, auroc = compute_eer_and_auroc(positives, negatives)\n",
    "        eer_total = eer_total + eer\n",
    "        auroc_total = auroc_total + auroc\n",
    "        \n",
    "    eer_average = eer_total/n_times\n",
    "    auroc_average = auroc_total/n_times\n",
    "    return eer_average, auroc_average, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eer_eval, auroc_eval, model = model_auroc(X_train, Y_train, X_eval, Y_eval, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Eval EER: %f\" % eer_eval)\n",
    "print(\"Eval AUROC: %f\" % auroc_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section for Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Some testing to ensure that files are read correctly, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Determine threshold at which to remove silence\n",
    "## By looking at plots\n",
    "[X_orig, sample_rate] = librosa.load(datapath+\"dataset_samples/file.wav\", sr=16000)\n",
    "X = (librosa.effects.trim(X_orig, top_db=35))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plot of original waveform\n",
    "librosa.display.waveplot(X_orig,sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plot of trimmed waveform\n",
    "librosa.display.waveplot(X,sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try extracting feature from one file\n",
    "X_orig, sample_rate = read_file(datapath+'dataset_samples/file.wav', 16000)\n",
    "X = (librosa.effects.trim(X_orig, top_db=35))[0]\n",
    "mfccs, chroma, zero_crossing_rate = extract_feature(X, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try playing audio\n",
    "[y,fs] = librosa.load(datapath+\"dataset_samples/file.wav\", sr=16000)\n",
    "Audio(data=y, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Anssi's Baseline Code on my Training/Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Because Anssi's Baseline Code used the Eval set as the validation set, and the rest as training sets\n",
    "## Also because I am missing about a quarter of the sound files\n",
    "## We have different datasets, hence I wanted to calculate the baseline using his code but my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fivenum calculator copied from Anssi's baseline code\n",
    "def fivenum(x, axis):\n",
    "    \"\"\" Computes five number summary along given axis\n",
    "    \n",
    "    x -- Input array\n",
    "    axis -- Axis along which five number summary should be computed.\n",
    "    Returns: Array where given axis is replaced with five number summary\n",
    "    \"\"\"\n",
    "    mi = x.min(axis=axis)\n",
    "    first_q = np.percentile(x, 25, axis=axis)\n",
    "    median = np.median(x, axis=axis)\n",
    "    third_q = np.percentile(x, 75, axis=axis)\n",
    "    ma = x.max(axis=axis)\n",
    "    return np.stack([mi, first_q, median, third_q, ma], axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculate fivenum on the MFCCs that I extracted\n",
    "mfccs5num = np.array([])\n",
    "for i in range(0, len(mfccsarr)):\n",
    "    mf = (fivenum(mfccsarr[i], 1)).ravel()\n",
    "    if (i==0):\n",
    "        mfccs5num = mf\n",
    "    else:\n",
    "        mfccs5num = np.vstack((mfccs5num, mf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put features into a single array to feed into NN\n",
    "featurearrtest = np.array([])\n",
    "for i in range(0, mfccs_meansarr.shape[0]):\n",
    "    featurelisttest = np.copy(mfccs5num[i,:])\n",
    "    if (i==0):\n",
    "        featurearrtest = np.copy(featurelisttest)\n",
    "    else:\n",
    "        featurearrtest = np.vstack((featurearrtest, featurelisttest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalise data by subtracting mean and dividing by standard deviation\n",
    "epsilon = 1e-8 # to prevent division by zero\n",
    "featurearr_normtest = np.zeros_like(featurearrtest)\n",
    "for i in range (0,featurearrtest.shape[1]):\n",
    "    featurearr_normtest[:,i] = (featurearrtest[:,i]-np.mean(featurearrtest[:,i]))/(np.std(featurearrtest[:,i] + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into evaluation and training-validation sets\n",
    "# Note: Evaluation set is the one for which the \"eval\" column says \"True\"\n",
    "# I will use the rest for experimentation, by splitting it into training and validation sets\n",
    "\n",
    "Y_evaltest = pds[np.where(evals == True)]\n",
    "X_evaltest = featurearr_normtest[np.where(evals == True)]\n",
    "Y_trainvaltest = pds[np.where(evals == False)]\n",
    "X_trainvaltest = featurearr_normtest[np.where(evals == False)]\n",
    "speakers_trainvaltest = ids[np.where(evals == False)] # Speaker ids who are not in eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split non-evaluation data again into training and validation sets\n",
    "# Ensure that the same speaker doesn't go into both sets (i.e. each speaker is only in one set)\n",
    "\n",
    "train_val_ratio = 1.5 # 60% training data; 40% validation data\n",
    "epsilon = 1e-6 # To prevent division by zero\n",
    "train_id_list = np.array([]) #Speaker ids assigned to training set\n",
    "val_id_list = np.array([]) #Speaker ids assigned to validation set\n",
    "X_traintest = np.array([])\n",
    "Y_traintest = np.array([])\n",
    "X_validationtest = np.array([])\n",
    "Y_validationtest = np.array([])\n",
    "istrain = True\n",
    "\n",
    "for i in range(0, len(speakers_trainvaltest)):\n",
    "    speaker = speakers_trainvaltest[i]\n",
    "    #print(speaker in train_id_list)\n",
    "    if speaker in train_id_list:\n",
    "        # If speaker is already assigned to training set, all his subsequent recordings are too\n",
    "        istrain = True\n",
    "    elif speaker in val_id_list:\n",
    "        # If speaker is already assigned to validation set, all his subsequent recordings are too\n",
    "        istrain = False\n",
    "    else:\n",
    "        # If we have more training points than we wanted, assign next speaker to validation set\n",
    "        if (len(Y_traintest)/(len(Y_validationtest) + epsilon) > 1.5):\n",
    "            istrain = False\n",
    "        # Otherwise assign to training set\n",
    "        else:\n",
    "            istrain = True\n",
    "    if istrain:\n",
    "        if (len(X_traintest) == 0):\n",
    "            X_traintest = X_trainvaltest[i,:]\n",
    "        else:\n",
    "            X_traintest = np.vstack((X_traintest, X_trainvaltest[i,:]))\n",
    "        Y_traintest = np.append(Y_traintest, Y_trainvaltest[i])\n",
    "        train_id_list = np.append(train_id_list, speaker)\n",
    "    else:\n",
    "        if (len(X_validationtest) == 0):\n",
    "            X_validationtest = X_trainvaltest[i,:]\n",
    "        else:\n",
    "            X_validationtest = np.vstack((X_validationtest, X_trainvaltest[i,:]))\n",
    "        Y_validationtest = np.append(Y_validationtest, Y_trainvaltest[i])\n",
    "        val_id_list = np.append(val_id_list, speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Train Logisic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modeltest = LogisticRegression()\n",
    "modeltest.fit(X_trainvaltest, Y_trainvaltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Evaluate baseline model\n",
    "Y_predictionstest = modeltest.predict(X_trainvaltest)\n",
    "Y_validation_predictionstest = modeltest.predict(X_evaltest)\n",
    "positivestest = np.ravel(Y_validation_predictionstest[np.where(Y_evaltest == 1)])\n",
    "negativestest = np.ravel(Y_validation_predictionstest[np.where(Y_evaltest == 0)])\n",
    "compute_eer_and_auroc(positivestest, negativestest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is lower than Anssi's reported result, probably because of the smaller training set I used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:uef35]",
   "language": "python",
   "name": "conda-env-uef35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
